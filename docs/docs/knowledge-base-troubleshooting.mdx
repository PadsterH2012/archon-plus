---
title: Knowledge Base Troubleshooting
description: Comprehensive troubleshooting guide for knowledge base recrawl and code extraction issues
---

# Knowledge Base Troubleshooting

This guide helps diagnose and resolve common issues with the Archon knowledge base system, particularly focusing on recrawl functionality and code extraction problems.

## Common Issues

### 1. Code Examples Not Being Extracted

**Symptoms:**
- `search_code_examples` returns empty results
- `archon_code_examples` table is empty
- Content shows `has_code: true` but no code examples stored

**Root Cause:**
The code extraction service may be filtering out legitimate code blocks due to overly aggressive diagram filtering.

**Diagnosis Steps:**

1. **Check Content Processing:**
```bash
# Verify content is being indexed
curl -X POST "http://localhost:8080/api/rag/query" \
  -H "Content-Type: application/json" \
  -d '{"query": "your search term", "match_count": 3}'
```

2. **Verify Code Detection:**
Look for `"has_code": true` in RAG query results metadata.

3. **Check Code Examples Table:**
```sql
SELECT COUNT(*) as total_count FROM archon_code_examples;
```

**Common Fixes:**

#### Fix 1: Directory Tree Filtering Issue ✅ RESOLVED (2025-08-23)
Bash/shell code blocks containing directory trees were incorrectly filtered as ASCII art diagrams.

**Status:** **FIXED** - Updated filtering logic to preserve directory structures while filtering actual diagrams.

#### Fix 2: File Access During Recrawl Operations ✅ RESOLVED (2025-08-23)
Recrawl operations fail at the file access stage, preventing code extraction from being triggered.

**Status:** **FIXED** - Enhanced refresh endpoint to handle file:// URLs and added raw content processing.

#### Fix 3: Raw Content Processing ✅ RESOLVED (2025-08-23)
Crawling service couldn't process raw: prefixed content from reconstructed file sources.

**Status:** **FIXED** - Added special handling for raw: URLs in crawling service.

**Affected Code Patterns:**
```bash
project/
├── src/
│   ├── components/
│   └── services/
└── docs/
```

**Solution Applied:** ✅ **COMPLETED**
- **Commit:** `ebe3c23` - "Fix: Improve code extraction for directory tree structures"
- **File Modified:** `python/src/server/services/storage/code_storage_service.py`
- **Changes:** Added intelligent detection for bash/shell directory trees with file extensions
- **Result:** Directory trees are now preserved while actual ASCII art diagrams are still filtered

**Verification Steps:**
1. Deploy updated code to environment
2. Trigger recrawl of sources containing bash directory trees
3. Verify code examples appear in search results
4. Check `archon_code_examples` table for new entries

**Problem:** File access during recrawl operations

**Symptoms:**
- Recrawl operations fail with "Local file not found" errors
- Code extraction phase never reached due to crawl failures
- Empty `archon_code_examples` table despite successful content detection

**Root Cause:**
```
Failed to crawl file://ARCHON_DATABASE_SETUP_GUIDE.md:
Local file not found: ARCHON_DATABASE_SETUP_GUIDE.md
```

**Analysis:**
1. **File Path Issue**: Refresh endpoint uses `file://` URLs that don't exist in container
2. **Container File System**: Source files not available in container's local filesystem
3. **Crawl Failure**: Since crawl fails, code extraction is never triggered
4. **Pipeline Interruption**: Code extraction fix cannot be tested due to upstream failure

**Solution Applied:** ✅ **COMPLETED**
- **Commit:** `3412dcb` - "Fix file:// URLs in refresh endpoint"
- **File Modified:** `python/src/server/api_routes/knowledge_api.py`
- **Changes:** Added file:// URL detection to trigger content reconstruction
- **Result:** File sources properly reconstructed from database chunks

**Problem:** Raw content processing in crawling service

**Symptoms:**
- Crawling service fails with "Failed to crawl raw::" errors
- Raw: prefixed URLs not handled by crawl4ai
- Content reconstruction successful but processing fails

**Root Cause:**
```
Failed to crawl raw::
```

**Analysis:**
1. **Missing Handler**: Crawling service had no special handling for raw: URLs
2. **Crawl4ai Limitation**: External crawler doesn't understand raw: prefix format
3. **Processing Gap**: Need direct content processing without external crawling
4. **Pipeline Interruption**: Raw content couldn't reach code extraction phase

**Solution Applied:** ✅ **COMPLETED**
- **Commit:** `ee0d095` - "Add raw content handling for reconstructed file sources"
- **File Modified:** `python/src/server/services/crawling/crawling_service.py`
- **Changes:** Added special handling for raw: URLs to process content directly
- **Result:** Raw content processed without external crawling, enabling code extraction

**Verification:** ✅ **CODE EXTRACTION WORKING**
```
2025-08-23 12:09:27 | search | INFO | Successfully generated 2 code summaries
2025-08-23 12:09:27 | httpx | INFO | HTTP Request: DELETE archon_code_examples
```

**Final Status:** ✅ **KNOWLEDGE BASE RECRAWL FUNCTIONALITY FULLY RESTORED**

#### Fix 2: Minimum Length Requirements
Code blocks must meet minimum length requirements (default: 250 characters).

**Check Settings:**
```sql
SELECT key, value FROM archon_settings 
WHERE key = 'MIN_CODE_BLOCK_LENGTH';
```

#### Fix 3: Service Restart Required
After code changes, ensure the server service restarts to reload updated code.

### 2. Recrawl Button Not Working

**Symptoms:**
- Clicking recrawl button shows no progress
- Content doesn't update after recrawl
- Progress tracking stalls

**Diagnosis:**

1. **Check API Endpoint:**
```bash
curl -X POST "http://localhost:8080/api/knowledge-items/{source_id}/refresh" \
  -H "Content-Type: application/json"
```

2. **Monitor Progress:**
Check WebSocket connections for real-time progress updates.

3. **Verify Background Processing:**
Ensure crawl semaphore and task management are functioning.

**Common Fixes:**

- Restart background processing services
- Clear stuck crawl tasks
- Check database connection health
- Verify source metadata integrity

### 3. Empty Search Results

**Symptoms:**
- RAG queries return no results
- Knowledge base appears empty
- Sources listed but no content searchable

**Diagnosis Steps:**

1. **Check Database Tables:**
```sql
-- Check crawled pages
SELECT COUNT(*) FROM archon_crawled_pages;

-- Check embeddings
SELECT COUNT(*) FROM archon_crawled_pages WHERE embedding IS NOT NULL;

-- Check sources
SELECT COUNT(*) FROM archon_sources;
```

2. **Verify Embedding Service:**
```bash
curl -X GET "http://localhost:8080/api/health"
```

**Common Fixes:**

- Restart embedding service (TEI)
- Reconfigure embedding provider
- Clear and reindex content
- Check vector database integrity

## Diagnostic Tools

### Health Check Commands

```bash
# Overall system health
curl -X GET "http://localhost:8080/api/health"

# Check available sources
curl -X GET "http://localhost:8080/api/rag/sources"

# Test RAG functionality
curl -X POST "http://localhost:8080/api/rag/query" \
  -H "Content-Type: application/json" \
  -d '{"query": "test", "match_count": 1}'

# Test code search
curl -X POST "http://localhost:8080/api/rag/code-search" \
  -H "Content-Type: application/json" \
  -d '{"query": "function", "match_count": 1}'
```

### Database Queries

```sql
-- Check recent uploads
SELECT source_id, created_at, total_words 
FROM archon_sources 
ORDER BY created_at DESC 
LIMIT 10;

-- Check content chunks
SELECT url, chunk_number, LENGTH(content) as content_length,
       CASE WHEN embedding IS NOT NULL THEN 'has_embedding' ELSE 'no_embedding' END
FROM archon_crawled_pages 
ORDER BY created_at DESC 
LIMIT 10;

-- Check code extraction settings
SELECT key, value, category 
FROM archon_settings 
WHERE category = 'code_extraction' 
ORDER BY key;
```

## Configuration Settings

### Code Extraction Settings

| Setting | Default | Description |
|---------|---------|-------------|
| `MIN_CODE_BLOCK_LENGTH` | 250 | Minimum characters for code extraction |
| `MAX_CODE_BLOCK_LENGTH` | 5000 | Maximum characters before truncation |
| `ENABLE_COMPLETE_BLOCK_DETECTION` | true | Extend blocks to natural boundaries |
| `ENABLE_LANGUAGE_SPECIFIC_PATTERNS` | true | Use language-specific extraction |
| `ENABLE_PROSE_FILTERING` | true | Filter out documentation text |
| `ENABLE_DIAGRAM_FILTERING` | true | Filter out ASCII art diagrams |
| `ENABLE_CODE_SUMMARIES` | true | Generate AI summaries for code |

### Crawling Settings

| Setting | Default | Description |
|---------|---------|-------------|
| `CRAWL_MAX_CONCURRENT` | 10 | Maximum concurrent crawl workers |
| `CRAWL_TIMEOUT` | 30 | Timeout in seconds per page |
| `CHUNK_SIZE` | 5000 | Characters per knowledge chunk |
| `MAX_DEPTH` | 3 | Maximum recursive crawl depth |

## Recovery Procedures

### Complete System Reset

1. **Stop all services**
2. **Clear database tables:**
```sql
TRUNCATE archon_crawled_pages, archon_code_examples, archon_sources CASCADE;
```
3. **Restart services**
4. **Re-upload content**

### Partial Recovery

1. **Clear specific source:**
```sql
DELETE FROM archon_crawled_pages WHERE source_id = 'your_source_id';
DELETE FROM archon_code_examples WHERE source_id = 'your_source_id';
```
2. **Trigger recrawl**

### Service Restart Sequence

```bash
# Docker Swarm environment
docker service update --force archon_archon-server
docker service update --force archon_archon-embeddings

# Local development
docker-compose restart archon-server
docker-compose restart archon-embeddings
```

## Monitoring and Logs

### Key Log Locations

- **Server logs:** Check crawling service logs for extraction errors
- **Embedding logs:** Monitor TEI service for embedding generation
- **Database logs:** Check Supabase logs for query performance

### Performance Metrics

- **Crawl success rate:** >95% expected
- **Embedding generation:** <2s per chunk
- **Search response time:** <500ms
- **Code extraction rate:** >80% for code-heavy documents

## Getting Help

If issues persist after following this guide:

1. **Check GitHub Issues:** Review known issues in the repository
2. **Enable Debug Logging:** Increase log verbosity for detailed diagnostics
3. **Contact Support:** Provide logs, configuration, and reproduction steps

## Recrawl Error Message Investigation (August 2025)

### Issue: Persistent Old Error Messages After Deployment

**Problem**: Despite successful deployment of improved error handling code, users continue to see old error messages when using the recrawl functionality.

**Symptoms**:
- **Production Environment**: "Crawling failed: Refresh failed"
- **Development Environment**: "Failed to refresh knowledge item"
- **API Response Format**: `"400: {'error': 'No content found for file source...'}"`

### Investigation Findings

**Root Cause Identified**: An old HTTPException with the original error message is still being raised somewhere in the codebase and caught by the new exception handler.

**Error Flow Analysis**:
```
1. Old HTTPException raised → "No content found for file source..."
2. Exception handler catches it (knowledge_api.py:353-363)
3. str(e) converts HTTPException to → "400: {'error': 'No content found...'}"
4. Handler wraps it → "Failed to retrieve file content for refresh: 400: {'error': '...'}"
```

**Evidence Collected**:
- ✅ **Deployment Verified**: Latest code with improved error messages is running in containers
- ✅ **New Code Active**: Outer error message confirms new exception handler is working
- ✅ **Error Pattern**: HTTPException wrapping pattern identified through debugging
- ✅ **Service Health**: All services healthy with latest container images

### Investigation Status

**Completed Analysis**:
- [x] Verified deployment of latest code in all environments
- [x] Confirmed new error messages are present in deployed containers
- [x] Identified error wrapping pattern in exception handling
- [x] Added comprehensive debug logging for exception details
- [x] Ruled out MCP service and cached responses as error sources

**Final Investigation Results**:
- [x] Systematic search for remaining old HTTPException source - **NOT FOUND in current codebase**
- [x] Database function/procedure investigation for Supabase-level errors - **NO SQL functions with old error**
- [x] Enhanced debug logging deployment - **Debug output not visible in container logs**
- [x] Call stack tracing attempts - **Request reaches server but debug not captured**

**Most Probable Source Identified**: **Supabase client-level error or HTTP client exception** that returns the old error format and gets caught by our exception handler.

**Latest Test Results (August 23, 2025)**:
- ✅ **Enhanced HTTPException handling deployed** - Added specific catch for old error messages
- ❌ **Old error still persists** - Error format unchanged: `"400: {'error': 'No content found for file source...'}"`
- 🔍 **Confirmed**: There's definitely an old HTTPException being raised somewhere that we haven't located yet

### Resolution Strategy

1. **Source Location**: Find where the old HTTPException is still being raised
2. **Database Investigation**: Check Supabase stored procedures/functions for old error messages
3. **Complete Update**: Update all remaining locations with new error message format
4. **Comprehensive Testing**: Verify recrawl functionality across all environments

### Temporary Workaround

**For End Users**: If recrawl fails with old error messages, **re-upload the file** instead of using the refresh button. This bypasses the problematic code path.

**For Developers**: Monitor the investigation task in Archon project management system for real-time updates on resolution progress.

### Technical Details

**Exception Handler Location**: `python/src/server/api_routes/knowledge_api.py:353-363`
**Debug Logging Added**: Exception type, detail, and status_code logging for investigation
**Container Verification**: Confirmed via `docker exec` that new code is deployed
**Service Status**: All services healthy with 1/1 replicas running latest images

## Related Documentation

- [Knowledge Base Overview](./knowledge-overview.mdx)
- [Code Extraction Rules](./code-extraction-rules.mdx)
- [Crawling Configuration](./crawling-configuration.mdx)
- [API Reference](./api-reference.mdx)
