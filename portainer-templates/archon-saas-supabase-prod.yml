version: '3.8'

# Archon Stack with SaaS Supabase - PRODUCTION ENVIRONMENT
# This template deploys Archon PROD using external Supabase (supabase.com)
# 
# Prerequisites:
# 1. Create a Supabase project at https://supabase.com
# 2. Get your SUPABASE_URL and SUPABASE_SERVICE_KEY from project settings
# 3. Run the database migration scripts in your Supabase SQL editor
#
# Services:
# - prod-archon-server: Core API and business logic (Port: 8181)
# - prod-archon-mcp: Model Context Protocol interface (Port: 8051)  
# - prod-archon-agents: AI operations and streaming (Port: 8052)
# - prod-archon-ui: Web interface (Port: 3737)

services:
  # Core Server Service (FastAPI + Socket.IO + Crawling)
  archon-server:
    image: hl-harbor.techpad.uk/archon/archon-server:latest
    environment:
      # Supabase Configuration (REQUIRED)
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
      
      # Service Discovery
      - SERVICE_DISCOVERY_MODE=docker_swarm
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      
      # Port Configuration
      - ARCHON_SERVER_PORT=${ARCHON_SERVER_PORT:-8181}
      - ARCHON_MCP_PORT=${ARCHON_MCP_PORT:-8051}
      - ARCHON_AGENTS_PORT=${ARCHON_AGENTS_PORT:-8052}
      
      # Optional: Logging
      - LOGFIRE_TOKEN=${LOGFIRE_TOKEN:-}
    ports:
      - target: 8181
        published: ${ARCHON_SERVER_PORT:-8181}
        protocol: tcp
        mode: ingress
    networks:
      - archon-network
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    healthcheck:
      test: ["CMD", "sh", "-c", "python -c \"import urllib.request; urllib.request.urlopen('http://localhost:8181/health')\""]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      replicas: 1
      placement:
        constraints:
          - node.role == manager
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          memory: 1G
          cpus: '1'
        reservations:
          memory: 512M
          cpus: '0.5'

  # Model Context Protocol Server
  archon-mcp:
    image: hl-harbor.techpad.uk/archon/archon-mcp:latest
    environment:
      # Supabase Configuration
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
      
      # Service Discovery
      - SERVICE_DISCOVERY_MODE=docker_swarm
      - TRANSPORT=sse
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      
      # Service URLs for inter-service communication
      - API_SERVICE_URL=http://archon-server:8181
      - AGENTS_SERVICE_URL=http://archon-agents:8052
      
      # Port Configuration
      - ARCHON_MCP_PORT=${ARCHON_MCP_PORT:-8051}
      - ARCHON_SERVER_PORT=${ARCHON_SERVER_PORT:-8181}
      - ARCHON_AGENTS_PORT=${ARCHON_AGENTS_PORT:-8052}
      
      # Optional: Logging
      - LOGFIRE_TOKEN=${LOGFIRE_TOKEN:-}
    ports:
      - target: 8051
        published: ${ARCHON_MCP_PORT:-8051}
        protocol: tcp
        mode: ingress
    networks:
      - archon-network
    healthcheck:
      test: ["CMD", "sh", "-c", "python -c \"import socket; s=socket.socket(); s.connect(('localhost', 8051)); s.close()\""]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    depends_on:
      - archon-server
      - archon-agents

  # AI Agents Service (ML/Reranking)
  archon-agents:
    image: hl-harbor.techpad.uk/archon/archon-agents:latest
    environment:
      # Supabase Configuration
      - SUPABASE_URL=${SUPABASE_URL}
      - SUPABASE_SERVICE_KEY=${SUPABASE_SERVICE_KEY}
      
      # Service Discovery
      - SERVICE_DISCOVERY_MODE=docker_swarm
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      
      # Port Configuration
      - ARCHON_AGENTS_PORT=${ARCHON_AGENTS_PORT:-8052}
      
      # Optional: Logging
      - LOGFIRE_TOKEN=${LOGFIRE_TOKEN:-}
    ports:
      - target: 8052
        published: ${ARCHON_AGENTS_PORT:-8052}
        protocol: tcp
        mode: ingress
    networks:
      - archon-network
    healthcheck:
      test: ["CMD", "sh", "-c", "python -c \"import urllib.request; urllib.request.urlopen('http://localhost:8052/health')\""]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          memory: 1G
          cpus: '1'
        reservations:
          memory: 512M
          cpus: '0.5'

  # Frontend Web Interface
  archon-ui:
    image: hl-harbor.techpad.uk/archon/archon-ui:latest
    environment:
      - VITE_API_URL=http://${HOST:-localhost}:${ARCHON_SERVER_PORT:-8181}
      - ARCHON_SERVER_PORT=${ARCHON_SERVER_PORT:-8181}
      - HOST=${HOST:-localhost}
    ports:
      - target: 5173
        published: ${ARCHON_UI_PORT:-3737}
        protocol: tcp
        mode: ingress
    networks:
      - archon-network
    # Override nginx command to use simple Python server instead
    command: >
      sh -c "
      echo 'Waiting for backend services to be ready...' &&
      sleep 45 &&
      echo 'Starting nginx...' &&
      nginx -g 'daemon off;'
      "
    healthcheck:
      test: ["CMD", "sh", "-c", "wget --no-verbose --tries=1 --spider http://localhost:5173 || exit 1"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s  # Increased from 30s
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 10s  # Increased delay
        max_attempts: 5  # Increased attempts
      resources:
        limits:
          memory: 512M
          cpus: '0.5'
        reservations:
          memory: 256M
          cpus: '0.25'
    depends_on:
      - archon-server

  # Text Embeddings Inference (TEI) - Local Embedding Server
  archon-embeddings:
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-1.8
    environment:
      - MODEL_ID=${EMBEDDING_MODEL_ID:-sentence-transformers/all-MiniLM-L6-v2}
      - MAX_CONCURRENT_REQUESTS=${TEI_MAX_CONCURRENT:-512}
      - MAX_BATCH_TOKENS=${TEI_MAX_BATCH_TOKENS:-16384}
      - MAX_BATCH_REQUESTS=${TEI_MAX_BATCH_REQUESTS:-32}
      - HOSTNAME=0.0.0.0
      - PORT=80
    ports:
      - target: 80
        published: ${ARCHON_EMBEDDINGS_PORT:-8080}
        protocol: tcp
        mode: ingress
    networks:
      - archon-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:80/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 60s
    deploy:
      replicas: 1
      restart_policy:
        condition: on-failure
        delay: 5s
        max_attempts: 3
      resources:
        limits:
          memory: ${TEI_MEMORY_LIMIT:-2G}
          cpus: ${TEI_CPU_LIMIT:-2}
        reservations:
          memory: ${TEI_MEMORY_RESERVATION:-1G}
          cpus: ${TEI_CPU_RESERVATION:-1}

networks:
  archon-network:
    driver: overlay
    attachable: true

# Environment Variables Required:
# SUPABASE_URL=https://your-project.supabase.co
# SUPABASE_SERVICE_KEY=your-service-key
#
# Optional Environment Variables:
# ARCHON_SERVER_PORT=8181
# ARCHON_MCP_PORT=8051
# ARCHON_AGENTS_PORT=8052
# ARCHON_UI_PORT=3737
# ARCHON_EMBEDDINGS_PORT=8080
# HOST=your-domain.com
# LOG_LEVEL=INFO
# LOGFIRE_TOKEN=your-logfire-token
#
# TEI Configuration:
# EMBEDDING_MODEL_ID=sentence-transformers/all-MiniLM-L6-v2
# TEI_MAX_CONCURRENT=512
# TEI_MAX_BATCH_TOKENS=16384
# TEI_MAX_BATCH_REQUESTS=32
# TEI_MEMORY_LIMIT=2G
# TEI_CPU_LIMIT=2
# TEI_MEMORY_RESERVATION=1G
# TEI_CPU_RESERVATION=1
